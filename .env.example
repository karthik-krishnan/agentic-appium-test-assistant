# LLM Provider Configuration
# Choose: 'openai' or 'ollama' (default: ollama)
LLM_PROVIDER=ollama

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4

# Ollama Configuration (if using Ollama - local open-source LLM)
# First install Ollama from: https://ollama.com/
# Then run: ollama pull llama3.1
OLLAMA_HOST=http://localhost:11434
# Recommended models: llama3.1, codellama, mistral, qwen2.5-coder
OLLAMA_MODEL=llama3.1
